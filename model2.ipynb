{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_13936\\1079467236.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_data = pd.concat([all_data, combined_df])\n",
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_13936\\1079467236.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  testing_data = pd.concat([testing_data, combined_df])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subjects = ['sub1.csv','sub2.csv','sub3.csv','sub4.csv','sub5.csv','sub6.csv','sub7.csv','sub8.csv','sub9.csv','sub10.csv','sub11.csv','sub12.csv','sub13.csv']\n",
    "unfiltered_subjects = ['Aanand_19_01.csv','Abhijeet_6205876348.csv', 'Achal_19_01.csv', 'Adit_18_02.csv', 'Deepanshu_21_02.csv', 'Mantavya_20_01.csv', 'Mantavya_20_02.csv', 'Pritesh_22_01.csv', 'Pritesh_22_02.csv', 'Rishab_20_01.csv', 'Rishab_20_02.csv']\n",
    "                         #'Aanand_19_02.csv'  #'Deepanshu_21_1.csv' <<== Let's use this to test...\n",
    "\n",
    "testing_subjects = ['Aanand_19_02.csv', 'Deepanshu_21_1.csv']\n",
    "sfreq = 120\n",
    "\n",
    "\n",
    "#For subjects:::::::::::::\n",
    "\n",
    "#ch_names = ['Fp2', 'F4', 'F8', 'T8', 'Fp1', 'F3', 'F7', 'T7', 'Cz',\n",
    "#            'C4', 'P4', 'O2', 'Pz', 'C3', 'P3', 'O1', 'STIM', 'label']\n",
    "\n",
    "# Create an empty DataFrame to store all data\n",
    "#all_data = pd.DataFrame(columns=ch_names)\n",
    "\n",
    "# for file_name in subjects:\n",
    "#     df = pd.read_csv(file_name, index_col=0)  # Specify index column\n",
    "#     df['timestamps'] = df['timestamps'] - df['timestamps'][0]\n",
    "    \n",
    "#     lvl1_sub = df[(df['timestamps'] >= 80) & (df['timestamps'] < 120)].copy()\n",
    "#     lvl2_sub = df[(df['timestamps'] >= 220) & (df['timestamps'] < 260)].copy()\n",
    "#     lvl3_sub = df[(df['timestamps'] >= 340) & (df['timestamps'] < 380)].copy()\n",
    "\n",
    "#     lvl1_sub['label'] = 1\n",
    "#     lvl2_sub['label'] = 2\n",
    "#     lvl3_sub['label'] = 3\n",
    "    \n",
    "#     combined_df = pd.concat([lvl1_sub, lvl2_sub, lvl3_sub])\n",
    "#     all_data = pd.concat([all_data, combined_df])\n",
    "\n",
    "#For unfiltered_subjects\n",
    "\n",
    "\n",
    "ch_names = ['timestamps','Fp1','Fp2','C3','C4','P7','P8','O1','O2','F7','F8','F3','F4','T7','T8','P3','P4','stim','sfreq']\n",
    "\n",
    "# Create an empty DataFrame to store all data\n",
    "all_data = pd.DataFrame(columns=ch_names)\n",
    "\n",
    "for file_name in unfiltered_subjects:\n",
    "    df = pd.read_csv(file_name)  # Specify index column\n",
    "    df['timestamps'] = df['timestamps'] - df['timestamps'][0]\n",
    "    \n",
    "    lvl1_sub = df[(df['timestamps'] >= 80) & (df['timestamps'] < 120)].copy()\n",
    "    lvl2_sub = df[(df['timestamps'] >= 220) & (df['timestamps'] < 260)].copy()\n",
    "    lvl3_sub = df[(df['timestamps'] >= 340) & (df['timestamps'] < 380)].copy()\n",
    "\n",
    "    lvl1_sub['label'] = 1\n",
    "    lvl2_sub['label'] = 2\n",
    "    lvl3_sub['label'] = 3\n",
    "    \n",
    "    combined_df = pd.concat([lvl1_sub, lvl2_sub, lvl3_sub])\n",
    "    all_data = pd.concat([all_data, combined_df])\n",
    "\n",
    "# Now all_data DataFrame contains data from all subjects\n",
    "# You can further process or save this DataFrame as needed\n",
    "\n",
    "\n",
    "ch_names = ['timestamps','Fp1','Fp2','C3','C4','P7','P8','O1','O2','F7','F8','F3','F4','T7','T8','P3','P4','stim','sfreq']\n",
    "\n",
    "# Create an empty DataFrame to store all data\n",
    "testing_data = pd.DataFrame(columns=ch_names)\n",
    "\n",
    "for file_name2 in testing_subjects:\n",
    "    df = pd.read_csv(file_name)  # Specify index column\n",
    "    df['timestamps'] = df['timestamps'] - df['timestamps'][0]\n",
    "    \n",
    "    lvl1_sub = df[(df['timestamps'] >= 80) & (df['timestamps'] < 120)].copy()\n",
    "    lvl2_sub = df[(df['timestamps'] >= 220) & (df['timestamps'] < 260)].copy()\n",
    "    lvl3_sub = df[(df['timestamps'] >= 340) & (df['timestamps'] < 380)].copy()\n",
    "\n",
    "    lvl1_sub['label'] = 1\n",
    "    lvl2_sub['label'] = 2\n",
    "    lvl3_sub['label'] = 3\n",
    "    \n",
    "    combined_df = pd.concat([lvl1_sub, lvl2_sub, lvl3_sub])\n",
    "    testing_data = pd.concat([testing_data, combined_df])\n",
    "\n",
    "\n",
    "#Testing Data is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop1 = all_data.drop(['sfreq'], axis=1)\n",
    "df = drop1.drop(['stim'], axis=1)\n",
    "\n",
    "\n",
    "drop_data = testing_data.drop(['sfreq'], axis=1)\n",
    "df2 = drop_data.drop(['stim'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (158735, 17)\n",
      "Shape of y: (158735,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = df.drop('label', axis=1)\n",
    "y_train = df['label']\n",
    "\n",
    "x_test = df2.drop('label', axis=1)\n",
    "y_test = df2['label']\n",
    "\n",
    "print(\"Shape of X:\", x_train.shape)\n",
    "print(\"Shape of y:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
