{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ssqueezepy\n",
    "!pip install timm\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors:  Dirk Gütlin <dirk.guetlin@gmail.com>\n",
    "#           Nicolas Barascud\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\"\"\"\n",
    "In asrpy.asr you can find the original ASR functions (similar to MATLAB)\n",
    "as well as a high-level ASR object ready to use with MNE-Python raw data.\n",
    "\"\"\"\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from numpy.linalg import pinv\n",
    "\n",
    "########################IMPORT########################\n",
    "\n",
    "# Authors:  Nicolas Barascud\n",
    "#           Dirk Gütlin <dirk.guetlin@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\"\"\"\n",
    "In asrpy.utils you can find utility functions required to perform ASR.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "from scipy.special import gamma, gammaincinv\n",
    "\n",
    "\n",
    "def fit_eeg_distribution(X, min_clean_fraction=0.25, max_dropout_fraction=0.1,\n",
    "                         fit_quantiles=[0.022, 0.6], step_sizes=[0.01, 0.01],\n",
    "                         shape_range=np.arange(1.7, 3.5, 0.15)):\n",
    "    \"\"\"Estimate the mean and SD of clean EEG from contaminated data.\n",
    "\n",
    "    This function estimates the mean and standard deviation of clean EEG from\n",
    "    a sample of amplitude values (that have preferably been computed over\n",
    "    short windows) that may include a large fraction of contaminated samples.\n",
    "    The clean EEG is assumed to represent a generalized Gaussian component in\n",
    "    a mixture with near-arbitrary artifact components. By default, at least\n",
    "    25% (`min_clean_fraction`) of the data must be clean EEG, and the rest\n",
    "    can be contaminated. No more than 10% (`max_dropout_fraction`) of the\n",
    "    data is allowed to come from contaminations that cause lower-than-EEG\n",
    "    amplitudes (e.g., sensor unplugged). There are no restrictions on\n",
    "    artifacts causing larger-than-EEG amplitudes, i.e., virtually anything is\n",
    "    handled (with the exception of a very unlikely type of distribution that\n",
    "    combines with the clean EEG samples into a larger symmetric generalized\n",
    "    Gaussian peak and thereby \"fools\" the estimator). The default parameters\n",
    "    should work for a wide range of applications but may be adapted to\n",
    "    accommodate special circumstances.\n",
    "    The method works by fitting a truncated generalized Gaussian whose\n",
    "    parameters are constrained by `min_clean_fraction`,\n",
    "    `max_dropout_fraction`, `fit_quantiles`, and `shape_range`. The fit is\n",
    "    performed by a grid search that always finds a close-to-optimal solution\n",
    "    if the above assumptions are fulfilled.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_channels, n_samples)\n",
    "        EEG data, possibly containing artifacts.\n",
    "    max_dropout_fraction : float\n",
    "        Maximum fraction that can have dropouts. This is the maximum fraction\n",
    "        of time windows that may have arbitrarily low amplitude (e.g., due to\n",
    "        the sensors being unplugged) (default=0.25).\n",
    "    min_clean_fraction : float\n",
    "        Minimum fraction that needs to be clean. This is the minimum fraction\n",
    "        of time windows that need to contain essentially uncontaminated EEG\n",
    "        (default=0.1).\n",
    "    fit_quantiles : 2-tuple\n",
    "        Quantile range [lower,upper] of the truncated generalized Gaussian\n",
    "        distribution that shall be fit to the EEG contents (default=[0.022\n",
    "        0.6]).\n",
    "    step_sizes : 2-tuple\n",
    "        Step size of the grid search; the first value is the stepping of the\n",
    "        lower bound (which essentially steps over any dropout samples), and\n",
    "        the second value is the stepping over possible scales (i.e., clean-\n",
    "        data quantiles) (default=[0.01, 0.01]).\n",
    "    beta : array\n",
    "        Range that the clean EEG distribution's shape parameter beta may take.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mu : array\n",
    "        Estimated mean of the clean EEG distribution.\n",
    "    sig : array\n",
    "        Estimated standard deviation of the clean EEG distribution.\n",
    "    alpha : float\n",
    "        Estimated scale parameter of the generalized Gaussian clean EEG\n",
    "        distribution.\n",
    "    beta : float\n",
    "        Estimated shape parameter of the generalized Gaussian clean EEG\n",
    "        distribution.\n",
    "\n",
    "    \"\"\"\n",
    "    # sort data so we can access quantiles directly\n",
    "    X = np.sort(X)\n",
    "    n = len(X)\n",
    "\n",
    "    # compute z bounds for the truncated standard generalized Gaussian pdf and\n",
    "    # pdf rescaler\n",
    "    quants = np.array(fit_quantiles)\n",
    "    zbounds = []\n",
    "    rescale = []\n",
    "    for b in range(len(shape_range)):\n",
    "        gam = gammaincinv(\n",
    "            1 / shape_range[b], np.sign(quants - 1 / 2) * (2 * quants - 1))\n",
    "        zbounds.append(np.sign(quants - 1 / 2) * gam ** (1 / shape_range[b]))\n",
    "        rescale.append(shape_range[b] / (2 * gamma(1 / shape_range[b])))\n",
    "\n",
    "    # determine the quantile-dependent limits for the grid search\n",
    "    # we can generally skip the tail below the lower quantile\n",
    "    lower_min = np.min(quants)\n",
    "    # maximum width is the fit interval if all data is clean\n",
    "    max_width = np.diff(quants)\n",
    "    # minimum width of the fit interval, as fraction of data\n",
    "    min_width = min_clean_fraction * max_width\n",
    "\n",
    "    # Build quantile interval matrix\n",
    "    cols = np.arange(lower_min,\n",
    "                     lower_min + max_dropout_fraction + step_sizes[0] * 1e-9,\n",
    "                     step_sizes[0])\n",
    "    cols = np.round(n * cols).astype(int)\n",
    "    rows = np.arange(0, int(np.round(n * max_width)))\n",
    "    newX = np.zeros((len(rows), len(cols)))\n",
    "    for i, c in enumerate(range(len(rows))):\n",
    "        newX[i] = X[c + cols]\n",
    "\n",
    "    # subtract baseline value for each interval\n",
    "    X1 = newX[0, :]\n",
    "    newX = newX - X1\n",
    "\n",
    "    opt_val = np.inf\n",
    "    opt_lu = np.inf\n",
    "    opt_bounds = np.inf\n",
    "    opt_beta = np.inf\n",
    "    gridsearch = np.round(n * np.arange(max_width, min_width, -step_sizes[1]))\n",
    "    for m in gridsearch.astype(int):\n",
    "        mcurr = m - 1\n",
    "        nbins = int(np.round(3 * np.log2(1 + m / 2)))\n",
    "        cols = nbins / newX[mcurr]\n",
    "        H = newX[:m] * cols\n",
    "\n",
    "        hist_all = []\n",
    "        for ih in range(len(cols)):\n",
    "            histcurr = np.histogram(H[:, ih], bins=np.arange(0, nbins + 1))\n",
    "            hist_all.append(histcurr[0])\n",
    "        hist_all = np.array(hist_all, dtype=int).T\n",
    "        hist_all = np.vstack((hist_all, np.zeros(len(cols), dtype=int)))\n",
    "        logq = np.log(hist_all + 0.01)\n",
    "\n",
    "        # for each shape value...\n",
    "        for k, b in enumerate(shape_range):\n",
    "            bounds = zbounds[k]\n",
    "            x = bounds[0] + np.arange(0.5, nbins + 0.5) / nbins * np.diff(bounds)  # noqa:E501\n",
    "            p = np.exp(-np.abs(x) ** b) * rescale[k]\n",
    "            p = p / np.sum(p)\n",
    "\n",
    "            # calc KL divergences\n",
    "            kl = np.sum(p * (np.log(p) - logq[:-1, :].T), axis=1) + np.log(m)\n",
    "\n",
    "            # update optimal parameters\n",
    "            min_val = np.min(kl)\n",
    "            idx = np.argmin(kl)\n",
    "            if min_val < opt_val:\n",
    "                opt_val = min_val\n",
    "                opt_beta = shape_range[k]\n",
    "                opt_bounds = bounds\n",
    "                opt_lu = [X1[idx], X1[idx] + newX[m - 1, idx]]\n",
    "\n",
    "    # recover distribution parameters at optimum\n",
    "    alpha = (opt_lu[1] - opt_lu[0]) / np.diff(opt_bounds)\n",
    "    mu = opt_lu[0] - opt_bounds[0] * alpha\n",
    "    beta = opt_beta\n",
    "\n",
    "    # calculate the distribution's standard deviation from alpha and beta\n",
    "    sig = np.sqrt((alpha ** 2) * gamma(3 / beta) / gamma(1 / beta))\n",
    "\n",
    "    return mu, sig, alpha, beta\n",
    "\n",
    "\n",
    "def yulewalk(order, F, M):\n",
    "    \"\"\"Recursive filter design using a least-squares method.\n",
    "\n",
    "    [B,A] = YULEWALK(N,F,M) finds the N-th order recursive filter\n",
    "    coefficients B and A such that the filter:\n",
    "    B(z)   b(1) + b(2)z^-1 + .... + b(n)z^-(n-1)\n",
    "    ---- = -------------------------------------\n",
    "    A(z)    1   + a(1)z^-1 + .... + a(n)z^-(n-1)\n",
    "    matches the magnitude frequency response given by vectors F and M.\n",
    "    The YULEWALK function performs a least squares fit in the time domain. The\n",
    "    denominator coefficients {a(1),...,a(NA)} are computed by the so called\n",
    "    \"modified Yule Walker\" equations, using NR correlation coefficients\n",
    "    computed by inverse Fourier transformation of the specified frequency\n",
    "    response H.\n",
    "    The numerator is computed by a four step procedure. First, a numerator\n",
    "    polynomial corresponding to an additive decomposition of the power\n",
    "    frequency response is computed. Next, the complete frequency response\n",
    "    corresponding to the numerator and denominator polynomials is evaluated.\n",
    "    Then a spectral factorization technique is used to obtain the impulse\n",
    "    response of the filter. Finally, the numerator polynomial is obtained by a\n",
    "    least squares fit to this impulse response. For a more detailed\n",
    "    explanation of the algorithm see [1]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    order : int\n",
    "        Filter order.\n",
    "    F : array\n",
    "        Normalised frequency breakpoints for the filter. The frequencies in F\n",
    "        must be between 0.0 and 1.0, with 1.0 corresponding to half the sample\n",
    "        rate. They must be in increasing order and start with 0.0 and end with\n",
    "        1.0.\n",
    "    M : array\n",
    "        Magnitude breakpoints for the filter such that PLOT(F,M) would show a\n",
    "        plot of the desired frequency response.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] B. Friedlander and B. Porat, \"The Modified Yule-Walker Method of\n",
    "           ARMA Spectral Estimation,\" IEEE Transactions on Aerospace\n",
    "           Electronic Systems, Vol. AES-20, No. 2, pp. 158-173, March 1984.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Design an 8th-order lowpass filter and overplot the desired\n",
    "    frequency response with the actual frequency response:\n",
    "    >>> f = [0, .6, .6, 1]         # Frequency breakpoints\n",
    "    >>> m = [1, 1, 0, 0]           # Magnitude breakpoints\n",
    "    >>> [b, a] = yulewalk(8, f, m) # Filter design using least-squares method\n",
    "\n",
    "    \"\"\"\n",
    "    F = np.asarray(F)\n",
    "    M = np.asarray(M)\n",
    "    npt = 512\n",
    "    lap = np.fix(npt / 25).astype(int)\n",
    "    mf = F.size\n",
    "    npt = npt + 1  # For [dc 1 2 ... nyquist].\n",
    "    Ht = np.array(np.zeros((1, npt)))\n",
    "    nint = mf - 1\n",
    "    df = np.diff(F)\n",
    "\n",
    "    nb = 0\n",
    "    Ht[0][0] = M[0]\n",
    "    for i in range(nint):\n",
    "        if df[i] == 0:\n",
    "            nb = nb - int(lap / 2)\n",
    "            ne = nb + lap\n",
    "        else:\n",
    "            ne = int(np.fix(F[i + 1] * npt)) - 1\n",
    "\n",
    "        j = np.arange(nb, ne + 1)\n",
    "        if ne == nb:\n",
    "            inc = 0\n",
    "        else:\n",
    "            inc = (j - nb) / (ne - nb)\n",
    "\n",
    "        Ht[0][nb:ne + 1] = np.array(inc * M[i + 1] + (1 - inc) * M[i])\n",
    "        nb = ne + 1\n",
    "\n",
    "    Ht = np.concatenate((Ht, Ht[0][-2:0:-1]), axis=None)\n",
    "    n = Ht.size\n",
    "    n2 = np.fix((n + 1) / 2)\n",
    "    nb = order\n",
    "    nr = 4 * order\n",
    "    nt = np.arange(0, nr)\n",
    "\n",
    "    # compute correlation function of magnitude squared response\n",
    "    R = np.real(np.fft.ifft(Ht * Ht))\n",
    "    R = R[0:nr] * (0.54 + 0.46 * np.cos(np.pi * nt / (nr - 1)))   # pick NR correlations  # noqa\n",
    "\n",
    "    # Form window to be used in extracting the right \"wing\" of two-sided\n",
    "    # covariance sequence\n",
    "    Rwindow = np.concatenate(\n",
    "        (1 / 2, np.ones((1, int(n2 - 1))), np.zeros((1, int(n - n2)))),\n",
    "        axis=None)\n",
    "    A = polystab(denf(R, order))  # compute denominator\n",
    "\n",
    "    # compute additive decomposition\n",
    "    Qh = numf(np.concatenate((R[0] / 2, R[1:nr]), axis=None), A, order)\n",
    "\n",
    "    # compute impulse response\n",
    "    _, Ss = 2 * np.real(signal.freqz(Qh, A, worN=n, whole=True))\n",
    "\n",
    "    hh = np.fft.ifft(\n",
    "        np.exp(np.fft.fft(Rwindow * np.fft.ifft(np.log(Ss, dtype=np.complex128))))  # noqa\n",
    "    )\n",
    "    B = np.real(numf(hh[0:nr], A, nb))\n",
    "\n",
    "    return B, A\n",
    "\n",
    "\n",
    "def yulewalk_filter(X, sfreq, zi=None, ab=None, axis=-1):\n",
    "    \"\"\"Yulewalk filter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape = (n_channels, n_samples)\n",
    "        Data to filter.\n",
    "    sfreq : float\n",
    "        Sampling frequency.\n",
    "    zi : array, shape=(n_channels, filter_order)\n",
    "        Initial conditions.\n",
    "    a, b : 2-tuple | None\n",
    "        Coefficients of an IIR filter that is used to shape the spectrum of\n",
    "        the signal when calculating artifact statistics. The output signal\n",
    "        does not go through this filter. This is an optional way to tune the\n",
    "        sensitivity of the algorithm to each frequency component of the\n",
    "        signal. The default filter is less sensitive at alpha and beta\n",
    "        frequencies and more sensitive at delta (blinks) and gamma (muscle)\n",
    "        frequencies.\n",
    "    axis : int\n",
    "        Axis to filter on (default=-1, corresponding to samples).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : array\n",
    "        Filtered data.\n",
    "    zf :  array, shape=(n_channels, filter_order)\n",
    "        Output filter state.\n",
    "    \"\"\"\n",
    "    # Set default IIR filter coefficients\n",
    "    if ab is None:\n",
    "        F = np.array([0, 2, 3, 13, 16, 40, np.minimum(\n",
    "            80.0, (sfreq / 2.0) - 1.0), sfreq / 2.0]) * 2.0 / sfreq\n",
    "        M = np.array([3, 0.75, 0.33, 0.33, 1, 1, 3, 3])\n",
    "        B, A = yulewalk(8, F, M)\n",
    "    else:\n",
    "        A, B = ab\n",
    "\n",
    "    # apply the signal shaping filter and initialize the IIR filter state\n",
    "    if zi is None:\n",
    "        out = signal.lfilter(B, A, X, axis=axis)\n",
    "        zf = None\n",
    "    else:\n",
    "        out, zf = signal.lfilter(B, A, X, zi=zi, axis=axis)\n",
    "\n",
    "    return out, zf\n",
    "\n",
    "\n",
    "def ma_filter(N, X, Zi):\n",
    "    \"\"\"Run a moving average filter over the data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        Length of the filter.\n",
    "    X : array, shape=(n_channels, n_samples)\n",
    "        The raw data.\n",
    "    Zi : array\n",
    "        The initial filter conditions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : array\n",
    "        The filtered data.\n",
    "    Zf : array\n",
    "        The new fiter conditions.\n",
    "    \"\"\"\n",
    "    if Zi is None:\n",
    "        Zi = np.zeros([len(X), N])\n",
    "\n",
    "    Y = np.concatenate([Zi, X], axis=1)\n",
    "    M = Y.shape[-1]\n",
    "    I_ = np.stack([np.arange(M - N),\n",
    "                   np.arange(N, M)]).astype(int)\n",
    "    S = (np.stack([-np.ones(M - N),\n",
    "                   np.ones(M - N)]) / N)\n",
    "    X = np.cumsum(np.multiply(Y[:, np.reshape(I_.T, -1)],\n",
    "                              np.reshape(S.T, [-1])), axis=-1)\n",
    "\n",
    "    X = X[:, 1::2]\n",
    "\n",
    "    Zf = np.concatenate([-(X[:, -1] * N - Y[:, -N])[:, np.newaxis],\n",
    "                         Y[:, -N + 1:]], axis=-1)\n",
    "    return X, Zf\n",
    "\n",
    "\n",
    "def geometric_median(X, tol=1e-5, max_iter=500):\n",
    "    \"\"\"Geometric median.\n",
    "\n",
    "    This code is adapted from [2]_ using the Vardi and Zhang algorithm\n",
    "    described in [1]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_observations, n_variables)\n",
    "        The data.\n",
    "    tol : float\n",
    "        Tolerance (default=1.e-5)\n",
    "    max_iter : int\n",
    "        Max number of iterations (default=500):\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y1 : array, shape=(n_variables,)\n",
    "        Geometric median over X.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Vardi, Y., & Zhang, C. H. (2000). The multivariate L1-median and\n",
    "       associated data depth. Proceedings of the National Academy of Sciences,\n",
    "       97(4), 1423-1426. https://doi.org/10.1073/pnas.97.4.1423\n",
    "    .. [2] https://stackoverflow.com/questions/30299267/\n",
    "\n",
    "    \"\"\"\n",
    "    y = np.mean(X, 0)  # initial value\n",
    "\n",
    "    i = 0\n",
    "    while i < max_iter:\n",
    "        D = cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1. / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros / r\n",
    "            y1 = max(0, 1 - rinv) * T + min(1, rinv) * y\n",
    "\n",
    "        if euclidean(y, y1) < tol:\n",
    "            return y1\n",
    "\n",
    "        y = y1\n",
    "        i += 1\n",
    "    else:\n",
    "        print(f\"Geometric median could converge in {i} iterations \"\n",
    "              f\"with a tolerance of {tol}\")\n",
    "\n",
    "\n",
    "def polystab(a):\n",
    "    \"\"\"Polynomial stabilization.\n",
    "\n",
    "    POLYSTAB(A), where A is a vector of polynomial coefficients,\n",
    "    stabilizes the polynomial with respect to the unit circle;\n",
    "    roots whose magnitudes are greater than one are reflected\n",
    "    inside the unit circle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array\n",
    "        The vector of polynomial coefficients.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    b : array\n",
    "        The stabilized polynomial.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Convert a linear-phase filter into a minimum-phase filter with the same\n",
    "    magnitude response.\n",
    "    >>> h = fir1(25,0.4);               # Window-based FIR filter design\n",
    "    >>> flag_linphase = islinphase(h)   # Determines if filter is linear phase\n",
    "    >>> hmin = polystab(h) * norm(h)/norm(polystab(h));\n",
    "    >>> flag_minphase = isminphase(hmin)# Determines if filter is min phase\n",
    "\n",
    "    \"\"\"\n",
    "    v = np.roots(a)\n",
    "    i = np.where(v != 0)\n",
    "    vs = 0.5 * (np.sign(np.abs(v[i]) - 1) + 1)\n",
    "    v[i] = (1 - vs) * v[i] + vs / np.conj(v[i])\n",
    "    ind = np.where(a != 0)\n",
    "    b = a[ind[0][0]] * np.poly(v)\n",
    "\n",
    "    # Return only real coefficients if input was real:\n",
    "    if not(np.sum(np.imag(a))):\n",
    "        b = np.real(b)\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "def numf(h, a, nb):\n",
    "    \"\"\"Get numerator B given impulse-response h of B/A and denominator A.\"\"\"\n",
    "    nh = np.max(h.size)\n",
    "    xn = np.concatenate((1, np.zeros((1, nh - 1))), axis=None)\n",
    "    impr = signal.lfilter(np.array([1.0]), a, xn)\n",
    "\n",
    "    b = np.linalg.lstsq(\n",
    "        toeplitz(impr, np.concatenate((1, np.zeros((1, nb))), axis=None)),\n",
    "        h.T, rcond=None)[0].T\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "def denf(R, na):\n",
    "    \"\"\"Compute order NA denominator A from covariances R(0)...R(nr).\"\"\"\n",
    "    nr = np.max(np.size(R))\n",
    "    Rm = toeplitz(R[na:nr - 1], R[na:0:-1])\n",
    "    Rhs = - R[na + 1:nr]\n",
    "    A = np.concatenate(\n",
    "        (1, np.linalg.lstsq(Rm, Rhs.T, rcond=None)[0].T), axis=None)\n",
    "    return A\n",
    "\n",
    "\n",
    "def block_covariance(data, window=128):\n",
    "    \"\"\"Compute blockwise covariance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array, shape=(n_chans, n_samples)\n",
    "        Input data (must be 2D)\n",
    "    window : int\n",
    "        Window size.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cov : array, shape=(n_blocks, n_chans, n_chans)\n",
    "        Block covariance.\n",
    "    \"\"\"\n",
    "    n_ch, n_times = data.shape\n",
    "    U = np.zeros([len(np.arange(0, n_times - 1, window)), n_ch**2])\n",
    "    data = data.T\n",
    "    for k in range(0, window):\n",
    "        idx_range = np.minimum(n_times - 1,\n",
    "                               np.arange(k, n_times + k - 2, window))\n",
    "        U = U + np.reshape(data[idx_range].reshape([-1, 1, n_ch]) *\n",
    "                           data[idx_range].reshape(-1, n_ch, 1), U.shape)\n",
    "\n",
    "    return np.array(U)\n",
    "\n",
    "\n",
    "########################IMPORT########################\n",
    "\n",
    "class ASR():\n",
    "    \"\"\"Artifact Subspace Reconstruction.\n",
    "\n",
    "    Artifact subspace reconstruction (ASR) is an automated, online,\n",
    "    component-based artifact removal method for removing transient or\n",
    "    large-amplitude artifacts in multi-channel EEG recordings [1]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sfreq : float\n",
    "        Sampling rate of the data, in Hz.\n",
    "    cutoff: float\n",
    "        Standard deviation cutoff for rejection. X portions whose variance\n",
    "        is larger than this threshold relative to the calibration data are\n",
    "        considered missing data and will be removed. The most aggressive value\n",
    "        that can be used without losing too much EEG is 2.5. Recommended to\n",
    "        use with more conservative values ranging from 20 - 30.\n",
    "        Defaults to 20.\n",
    "    blocksize : int\n",
    "        Block size for calculating the robust data covariance and thresholds,\n",
    "        in samples; allows to reduce the memory and time requirements of the\n",
    "        robust estimators by this factor (down to Channels x Channels x Samples\n",
    "        x 16 / Blocksize bytes) (default=100).\n",
    "    win_len : float\n",
    "        Window length (s) that is used to check the data for artifact content.\n",
    "        This is ideally as long as the expected time scale of the artifacts but\n",
    "        not shorter than half a cycle of the high-pass filter that was used\n",
    "        (default=0.5).\n",
    "    win_overlap : float\n",
    "        Window overlap fraction. The fraction of two successive windows that\n",
    "        overlaps. Higher overlap ensures that fewer artifact portions are going\n",
    "        to be missed, but is slower (default=0.66).\n",
    "    max_dropout_fraction : float\n",
    "        Maximum fraction of windows that can be subject to signal dropouts\n",
    "        (e.g., sensor unplugged), used for threshold estimation (default=0.1).\n",
    "    min_clean_fraction : float\n",
    "        Minimum fraction of windows that need to be clean, used for threshold\n",
    "        estimation (default=0.25).\n",
    "    ab : 2-tuple | None\n",
    "        Coefficients (A, B) of an IIR filter that is used to shape the\n",
    "        spectrum of the signal when calculating artifact statistics. The\n",
    "        output signal does not go through this filter. This is an optional way\n",
    "        to tune the sensitivity of the algorithm to each frequency component\n",
    "        of the signal. The default filter is less sensitive at alpha and beta\n",
    "        frequencies and more sensitive at delta (blinks) and gamma (muscle)\n",
    "        frequencies. Defaults to None.\n",
    "    max_bad_chans : float\n",
    "        The maximum number or fraction of bad channels that a retained window\n",
    "        may still contain (more than this and it is removed). Reasonable range\n",
    "        is 0.05 (very clean output) to 0.3 (very lax cleaning of only coarse\n",
    "        artifacts) (default=0.2).\n",
    "    method : {'riemann', 'euclid'}\n",
    "        Method to use. If riemann, use the riemannian-modified version of\n",
    "        ASR [2]_. Currently, only euclidean ASR is supported. Defaults to\n",
    "        \"euclid\".\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    sfreq: array, shape=(n_channels, filter_order)\n",
    "        Filter initial conditions.\n",
    "    cutoff: float\n",
    "        Standard deviation cutoff for rejection.\n",
    "    blocksize : int\n",
    "        Block size for calculating the robust data covariance and thresholds.\n",
    "    win_len : float\n",
    "        Window length (s) that is used to check the data for artifact content.\n",
    "    win_overlap : float\n",
    "        Window overlap fraction.\n",
    "    max_dropout_fraction : float\n",
    "        Maximum fraction of windows that can be subject to signal dropouts.\n",
    "    min_clean_fraction : float\n",
    "        Minimum fraction of windows.\n",
    "    max_bad_chans : float\n",
    "        The maximum fraction of bad channels.\n",
    "    method : {'riemann', 'euclid'}\n",
    "        Method to use.\n",
    "    A, B: arrays\n",
    "        Coefficients of an IIR filter that is used to shape the spectrum of the\n",
    "        signal when calculating artifact statistics. The output signal does not\n",
    "        go through this filter. This is an optional way to tune the sensitivity\n",
    "        of the algorithm to each frequency component of the signal. The default\n",
    "        filter is less sensitive at alpha and beta frequencies and more\n",
    "        sensitive at delta (blinks) and gamma (muscle) frequencies.\n",
    "    M : array, shape=(channels, channels)\n",
    "        The mixing matrix to fit ASR data.\n",
    "    T : array, shape=(channels, channels)\n",
    "        The mixing matrix to fit ASR data.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Kothe, C. A. E., & Jung, T. P. (2016). U.S. Patent Application No.\n",
    "       14/895,440. https://patents.google.com/patent/US20160113587A1/en\n",
    "    .. [2] Blum, S., Jacobsen, N. S. J., Bleichner, M. G., & Debener, S.\n",
    "       (2019). A Riemannian Modification of Artifact Subspace Reconstruction\n",
    "       for EEG Artifact Handling. Frontiers in Human Neuroscience, 13.\n",
    "       https://doi.org/10.3389/fnhum.2019.00141\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sfreq, cutoff=20, blocksize=100, win_len=0.5,\n",
    "                 win_overlap=0.66, max_dropout_fraction=0.1,\n",
    "                 min_clean_fraction=0.25, ab=None, max_bad_chans=0.1,\n",
    "                 method=\"euclid\"):\n",
    "\n",
    "        # set attributes\n",
    "        self.sfreq = sfreq\n",
    "        self.cutoff = cutoff\n",
    "        self.blocksize = blocksize\n",
    "        self.win_len = win_len\n",
    "        self.win_overlap = win_overlap\n",
    "        self.max_dropout_fraction = max_dropout_fraction\n",
    "        self.min_clean_fraction = min_clean_fraction\n",
    "        self.max_bad_chans = max_bad_chans\n",
    "        self.method = \"euclid\"  # NOTE: riemann is not yet available\n",
    "        self._fitted = False\n",
    "\n",
    "        # set default yule-walker filter\n",
    "        if ab is None:\n",
    "            yw_f = np.array([0, 2, 3, 13, 16, 40,\n",
    "                             np.minimum(80.0, (self.sfreq / 2.0) - 1.0),\n",
    "                             self.sfreq / 2.0]) * 2.0 / self.sfreq\n",
    "            yw_m = np.array([3, 0.75, 0.33, 0.33, 1, 1, 3, 3])\n",
    "            self.B, self.A = yulewalk(8, yw_f, yw_m)\n",
    "        else:\n",
    "            self.A, self.B = ab\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"Reset state variables.\"\"\"\n",
    "        self.M = None\n",
    "        self.T = None\n",
    "\n",
    "        # TODO: The following parameters are effectively not used. Still,\n",
    "        #  they can be set manually via asr.transform(return_states=True)\n",
    "        self.R = None\n",
    "        self.carry = None\n",
    "        self.Zi = None\n",
    "        self.cov = None\n",
    "        self._fitted = False\n",
    "\n",
    "    def fit(self, raw, picks=\"eeg\", start=0, stop=None,\n",
    "            return_clean_window=False):\n",
    "        \"\"\"Calibration for the Artifact Subspace Reconstruction method.\n",
    "\n",
    "        The input to this data is a multi-channel time series of calibration\n",
    "        data. In typical uses the calibration data is clean resting EEG data\n",
    "        of data if the fraction of artifact content is below the breakdown\n",
    "        point of the robust statistics used for estimation (50% theoretical,\n",
    "        ~30% practical). If the data has a proportion of more than 30-50%\n",
    "        artifacts then bad time windows should be removed beforehand. This\n",
    "        data is used to estimate the thresholds that are used by the ASR\n",
    "        processing function to identify and remove artifact components.\n",
    "\n",
    "        The calibration data must have been recorded for the same cap design\n",
    "        from which data for cleanup will be recorded, and ideally should be\n",
    "        from the same session and same subject, but it is possible to reuse\n",
    "        the calibration data from a previous session and montage to the\n",
    "        extent that the cap is placed in the same location (where loss in\n",
    "        accuracy is more or less proportional to the mismatch in cap\n",
    "        placement).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        raw : instance of mne.io.Raw\n",
    "            Instance of mne.io.Raw to be used for fitting the ASR.\n",
    "            The calibration data should have been high-pass filtered (for\n",
    "            example at 0.5Hz or 1Hz using a Butterworth IIR filter), and be\n",
    "            reasonably clean not less than 30 seconds (this method is\n",
    "            typically used with 1 minute or more).\n",
    "        picks : str | list | slice | None\n",
    "            Channels used to fit the ASR. All channels should be of the same\n",
    "            type (e.g. \"eeg\", \"grads\"). Slices and lists of integers will\n",
    "            be interpreted as channel indices. In lists, channel\n",
    "            name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given\n",
    "            channels. Note that channels in info['bads'] will be included if\n",
    "            their names or indices are explicitly provided. Defaults to \"eeg\".\n",
    "        start : int\n",
    "            The first sample to use for fitting the data. Defaults to 0.\n",
    "        stop : int | None\n",
    "            The last sample to use for fitting the data. If `None`, all\n",
    "            samples after `start` will be used for fitting. Defaults to None.\n",
    "        return_clean_window : Bool\n",
    "            If True, the method will return the variables `clean` (the cropped\n",
    "             dataset which was used to fit the ASR) and `sample_mask` (a\n",
    "             logical mask of which samples were included/excluded from fitting\n",
    "             the ASR). Defaults to False.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        clean : array, shape=(n_channels, n_samples)\n",
    "            The cropped version of the dataset which was used to calibrate\n",
    "            the ASR. This array is a result of the `clean_windows` function\n",
    "            and no ASR was applied to it.\n",
    "        sample_mask : boolean array, shape=(1, n_samples)\n",
    "            Logical mask of the samples which were used to train the ASR.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # extract the data\n",
    "        X = raw.get_data(picks=picks, start=start, stop=stop)\n",
    "\n",
    "        # Find artifact-free windows first\n",
    "        clean, sample_mask = clean_windows(\n",
    "            X,\n",
    "            sfreq=self.sfreq,\n",
    "            win_len=self.win_len,\n",
    "            win_overlap=self.win_overlap,\n",
    "            max_bad_chans=self.max_bad_chans,\n",
    "            min_clean_fraction=self.min_clean_fraction,\n",
    "            max_dropout_fraction=self.max_dropout_fraction)\n",
    "\n",
    "        # Perform calibration\n",
    "        self.M, self.T = asr_calibrate(\n",
    "            clean,\n",
    "            sfreq=self.sfreq,\n",
    "            cutoff=self.cutoff,\n",
    "            blocksize=self.blocksize,\n",
    "            win_len=self.win_len,\n",
    "            win_overlap=self.win_overlap,\n",
    "            max_dropout_fraction=self.max_dropout_fraction,\n",
    "            min_clean_fraction=self.min_clean_fraction,\n",
    "            ab=(self.A, self.B),\n",
    "            method=self.method)\n",
    "\n",
    "        self._fitted = True\n",
    "\n",
    "        # return data if required\n",
    "        if return_clean_window:\n",
    "            return clean, sample_mask\n",
    "\n",
    "    def transform(self, raw, picks=\"eeg\", lookahead=0.25, stepsize=32,\n",
    "                  maxdims=0.66, return_states=False, mem_splits=3):\n",
    "        \"\"\"Apply Artifact Subspace Reconstruction.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        raw : instance of mne.io.Raw\n",
    "            Instance of mne.io.Raw to be transformed by the ASR.\n",
    "        picks : str | list | slice | None\n",
    "            Channels to be transformed by the ASR. Should be the same set of\n",
    "            channels as used by `ASR.fit()`. All channels should be of the\n",
    "            same type (e.g. \"eeg\", \"grads\"). Slices and lists of integers will\n",
    "            be interpreted as channel indices. In lists, channel\n",
    "            name strings (e.g., ['MEG0111', 'MEG2623'] will pick the given\n",
    "            channels. Note that channels in info['bads'] will be included if\n",
    "            their names or indices are explicitly provided. Defaults to \"eeg\".\n",
    "        lookahead : float\n",
    "            Amount of look-ahead that the algorithm should use (in seconds).\n",
    "            This value should be between 0 (no lookahead) and WindowLength/2\n",
    "            (optimal lookahead). The recommended value is WindowLength/2.\n",
    "            Default: 0.25\n",
    "\n",
    "            Note: Other than in `asr_process`, the signal will be readjusted\n",
    "            to eliminate any temporal jitter and automatically readjust it to\n",
    "            the correct time points. Zero-padding will be applied to the last\n",
    "            `lookahead` portion of the data, possibly resulting in inaccuracies\n",
    "            for the final `lookahead` seconds of the recording.\n",
    "        stepsize : int\n",
    "            The steps in which the algorithm will be updated. The larger this\n",
    "            is, the faster the algorithm will be. The value must not be larger\n",
    "            than WindowLength * SamplingRate. The minimum value is 1 (update\n",
    "            for every sample) while a good value would be sfreq//3. Note that\n",
    "            an update is always performed also on the first and last sample of\n",
    "            the data chunk. Default: 32\n",
    "        max_dims : float, int\n",
    "            Maximum dimensionality of artifacts to remove. This parameter\n",
    "            denotes the maximum number of dimensions which can be removed from\n",
    "            each segment. If larger than 1, `int(max_dims)` will denote the\n",
    "            maximum number of dimensions removed from the data. If smaller\n",
    "            than 1, `max_dims` describes a fraction of total dimensions.\n",
    "            Defaults to 0.66.\n",
    "        return_states : bool\n",
    "            If True, returns a dict including the updated states {\"M\":M,\n",
    "            \"T\":T, \"R\":R, \"Zi\":Zi, \"cov\":cov, \"carry\":carry}. Defaults to\n",
    "            False.\n",
    "        mem_splits : int\n",
    "            Split the array in `mem_splits` segments to save memory.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : array, shape=(n_channels, n_samples)\n",
    "            Filtered data.\n",
    "\n",
    "        \"\"\"\n",
    "        # extract the data\n",
    "        X = raw.get_data(picks=picks)\n",
    "\n",
    "        # add lookahead padding at the end\n",
    "        lookahead_samples = int(self.sfreq * lookahead)\n",
    "        X = np.concatenate([X,\n",
    "                            np.zeros([X.shape[0], lookahead_samples])],\n",
    "                          axis=1)\n",
    "\n",
    "        # apply ASR\n",
    "        X = asr_process(X, self.sfreq, self.M, self.T, self.win_len,\n",
    "                        lookahead, stepsize, maxdims, (self.A, self.B),\n",
    "                        self.R, self.Zi, self.cov, self.carry,\n",
    "                        return_states, self.method, mem_splits)\n",
    "\n",
    "        # remove lookahead portion from start\n",
    "        X = X[:, lookahead_samples:]\n",
    "\n",
    "        # Return a modifier raw instance\n",
    "        raw = raw.copy()\n",
    "        raw.apply_function(lambda x: X, picks=picks,\n",
    "                           channel_wise=False)\n",
    "        return raw\n",
    "\n",
    "\n",
    "def asr_calibrate(X, sfreq, cutoff=20, blocksize=100, win_len=0.5,\n",
    "                  win_overlap=0.66, max_dropout_fraction=0.1,\n",
    "                  min_clean_fraction=0.25, ab=None, method='euclid'):\n",
    "    \"\"\"Calibration function for the Artifact Subspace Reconstruction method.\n",
    "\n",
    "    This function can be used if you inted to apply ASR to a simple numpy\n",
    "    array instead of a mne.io.Raw object. It is equivalent to the MATLAB\n",
    "    implementation of asr_calibrate (except for some small differences\n",
    "    introduced by solvers for the eigenspace functions etc).\n",
    "\n",
    "    The input to this data is a multi-channel time series of calibration data.\n",
    "    In typical uses the calibration data is clean resting EEG data of ca. 1\n",
    "    minute duration (can also be longer). One can also use on-task data if the\n",
    "    fraction of artifact content is below the breakdown point of the robust\n",
    "    statistics used for estimation (50% theoretical, ~30% practical). If the\n",
    "    data has a proportion of more than 30-50% artifacts then bad time windows\n",
    "    should be removed beforehand. This data is used to estimate the thresholds\n",
    "    that are used by the ASR processing function to identify and remove\n",
    "    artifact components.\n",
    "\n",
    "    The calibration data must have been recorded for the same cap design from\n",
    "    which data for cleanup will be recorded, and ideally should be from the\n",
    "    same session and same subject, but it is possible to reuse the calibration\n",
    "    data from a previous session and montage to the extent that the cap is\n",
    "    placed in the same location (where loss in accuracy is more or less\n",
    "    proportional to the mismatch in cap placement).\n",
    "\n",
    "    The calibration data should have been high-pass filtered (for example at\n",
    "    0.5Hz or 1Hz using a Butterworth IIR filter).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_channels, n_samples)\n",
    "        *zero-mean* (e.g., high-pass filtered) and reasonably clean EEG of not\n",
    "        much less than 30 seconds (this method is typically used with 1 minute\n",
    "        or more).\n",
    "    sfreq : float\n",
    "        Sampling rate of the data, in Hz.\n",
    "    cutoff: float\n",
    "        Standard deviation cutoff for rejection. X portions whose variance\n",
    "        is larger than this threshold relative to the calibration data are\n",
    "        considered missing data and will be removed. Defaults to 20\n",
    "        (In EEGLab's `clean_rawdata` the original threshold was set to 5, but\n",
    "        it is widely recommended to use a value higher than 20).\n",
    "    blocksize : int\n",
    "        Block size for calculating the robust data covariance and thresholds,\n",
    "        in samples; allows to reduce the memory and time requirements of the\n",
    "        robust estimators by this factor (down to n_chans x n_chans x\n",
    "        n_samples x 16 / blocksize bytes) (default=100).\n",
    "    win_len : float\n",
    "        Window length that is used to check the data for artifact content.\n",
    "        This is ideally as long as the expected time scale of the artifacts\n",
    "        but short enough to allow for several 1000 windows to compute\n",
    "        statistics over (default=0.5).\n",
    "    win_overlap : float\n",
    "        Window overlap fraction. The fraction of two successive windows that\n",
    "        overlaps. Higher overlap ensures that fewer artifact portions are\n",
    "        going to be missed, but is slower (default=0.66).\n",
    "    max_dropout_fraction : float\n",
    "        Maximum fraction of windows that can be subject to signal dropouts\n",
    "        (e.g., sensor unplugged), used for threshold estimation (default=0.1).\n",
    "    min_clean_fraction : float\n",
    "        Minimum fraction of windows that need to be clean, used for threshold\n",
    "        estimation (default=0.25).\n",
    "    ab : 2-tuple | None\n",
    "        Coefficients (A, B) of an IIR filter that is used to shape the\n",
    "        spectrum of the signal when calculating artifact statistics. The\n",
    "        output signal does not go through this filter. This is an optional way\n",
    "        to tune the sensitivity of the algorithm to each frequency component\n",
    "        of the signal. The default filter is less sensitive at alpha and beta\n",
    "        frequencies and more sensitive at delta (blinks) and gamma (muscle)\n",
    "        frequencies. Defaults to None.\n",
    "    method : {'euclid', 'riemann'}\n",
    "        Metric to compute the covariance matrix average. For now, only\n",
    "        euclidean ASR is supported.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    M : array\n",
    "        Mixing matrix.\n",
    "    T : array\n",
    "        Threshold matrix.\n",
    "\n",
    "    \"\"\"\n",
    "    if method == \"riemann\":\n",
    "        warnings.warn(\"Riemannian ASR is not yet supported. Switching back to\"\n",
    "                      \" Euclidean ASR.\")\n",
    "        method == \"euclid\"\n",
    "\n",
    "    logging.debug('[ASR] Calibrating...')\n",
    "\n",
    "    # set number of channels and number of samples\n",
    "    [nc, ns] = X.shape\n",
    "\n",
    "    # filter the data\n",
    "    X, _zf = yulewalk_filter(X, sfreq, ab=ab)\n",
    "\n",
    "    # window length for calculating thresholds\n",
    "    N = int(np.round(win_len * sfreq))\n",
    "\n",
    "    # get block covariances\n",
    "    U = block_covariance(X, window=blocksize)\n",
    "\n",
    "    # get geometric median for each block\n",
    "    # Note: riemann mode is not yet supported, else this could be:\n",
    "    # Uavg = pyriemann.utils.mean_covariance(U, metric='riemann')\n",
    "    Uavg = geometric_median(U.reshape((-1, nc * nc)) / blocksize)\n",
    "    Uavg = Uavg.reshape((nc, nc))\n",
    "\n",
    "    # get the mixing matrix M\n",
    "    M = linalg.sqrtm(np.real(Uavg))\n",
    "\n",
    "    # sort the get the sorted eigenvecotors/eigenvalues\n",
    "    # riemann is not yet supported, else this could be PGA/nonlinear eigenvs\n",
    "    D, Vtmp = linalg.eigh(M)\n",
    "    V = Vtmp[:, np.argsort(D)]  # I think numpy sorts them automatically\n",
    "\n",
    "    # get the threshold matrix T\n",
    "    x = np.abs(np.dot(V.T, X))\n",
    "    offsets = np.int_(np.arange(0, ns - N, np.round(N * (1 - win_overlap))))\n",
    "\n",
    "    # go through all the channels and fit the EEG distribution\n",
    "    mu = np.zeros(nc)\n",
    "    sig = np.zeros(nc)\n",
    "    for ichan in reversed(range(nc)):\n",
    "        rms = x[ichan, :] ** 2\n",
    "        Y = []\n",
    "        for o in offsets:\n",
    "            Y.append(np.sqrt(np.sum(rms[o:o + N]) / N))\n",
    "        mu[ichan], sig[ichan], alpha, beta = fit_eeg_distribution(\n",
    "            Y, min_clean_fraction, max_dropout_fraction)\n",
    "    T = np.dot(np.diag(mu + cutoff * sig), V.T)\n",
    "\n",
    "    logging.debug('[ASR] Calibration done.')\n",
    "    return M, T\n",
    "\n",
    "\n",
    "def asr_process(data, sfreq, M, T, windowlen=0.5, lookahead=0.25, stepsize=32,\n",
    "                maxdims=0.66, ab=None, R=None, Zi=None, cov=None, carry=None,\n",
    "                return_states=False, method=\"euclid\", mem_splits=3):\n",
    "    \"\"\"Apply the Artifact Subspace Reconstruction method to a data array.\n",
    "\n",
    "    This function is used to clean multi-channel signal using the ASR method.\n",
    "    The required inputs are the data matrix and the sampling rate of the data.\n",
    "\n",
    "    `asr_process` can be used if you inted to apply ASR to a simple numpy\n",
    "    array instead of a mne.io.Raw object. It is equivalent to the MATLAB\n",
    "    implementation of `asr_process` (except for some small differences\n",
    "    introduced by solvers for the eigenspace functions etc).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array, shape=(n_channels, n_samples)\n",
    "        Raw data.\n",
    "    sfreq : float\n",
    "        The sampling rate of the data.\n",
    "    M : array, shape=(n_channels, n_channels)\n",
    "        The Mixing matrix (as fitted with asr_calibrate).\n",
    "    T : array, shape=(n_channels, n_channels)\n",
    "        The Threshold matrix (as fitted with asr_calibrate).\n",
    "    windowlen : float\n",
    "        Window length that is used to check the data for artifact content.\n",
    "        This is ideally as long as the expected time scale of the artifacts\n",
    "        but short enough to allow for several 1000 windows to compute\n",
    "        statistics over (default=0.5).\n",
    "    lookahead:\n",
    "        Amount of look-ahead that the algorithm should use. Since the\n",
    "        processing is causal, the output signal will be delayed by this\n",
    "        amount. This value is in seconds and should be between 0 (no\n",
    "        lookahead) and WindowLength/2 (optimal lookahead). The recommended\n",
    "        value is WindowLength/2. Default: 0.25\n",
    "    stepsize:\n",
    "        The steps in which the algorithm will be updated. The larger this is,\n",
    "        the faster the algorithm will be. The value must not be larger than\n",
    "        WindowLength * SamplingRate. The minimum value is 1 (update for every\n",
    "        sample) while a good value would be sfreq//3. Note that an update\n",
    "        is always performed also on the first and last sample of the data\n",
    "        chunk. Default: 32\n",
    "    max_dims : float, int\n",
    "        Maximum dimensionality of artifacts to remove. This parameter\n",
    "        denotes the maximum number of dimensions which can be removed from\n",
    "        each segment. If larger than 1, `int(max_dims)` will denote the\n",
    "        maximum number of dimensions removed from the data. If smaller than 1,\n",
    "        `max_dims` describes a fraction of total dimensions. Defaults to 0.66.\n",
    "    ab : 2-tuple | None\n",
    "        Coefficients (A, B) of an IIR filter that is used to shape the\n",
    "        spectrum of the signal when calculating artifact statistics. The\n",
    "        output signal does not go through this filter. This is an optional way\n",
    "        to tune the sensitivity of the algorithm to each frequency component\n",
    "        of the signal. The default filter is less sensitive at alpha and beta\n",
    "        frequencies and more sensitive at delta (blinks) and gamma (muscle)\n",
    "        frequencies. Defaults to None.\n",
    "    R : array, shape=(n_channels, n_channels)\n",
    "        Previous reconstruction matrix. Defaults to None.\n",
    "    Zi : array\n",
    "        Previous filter conditions. Defaults to None.\n",
    "    cov : array, shape=([n_trials, ]n_channels, n_channels) | None\n",
    "        Covariance. If None (default), then it is computed from ``X_filt``.\n",
    "        If a 3D array is provided, the average covariance is computed from\n",
    "        all the elements in it. Defaults to None.\n",
    "    carry :\n",
    "        Initial portion of the data that will be added to the current data.\n",
    "        If None, data will be interpolated. Defaults to None.\n",
    "    return_states : bool\n",
    "        If True, returns a dict including the updated states {\"M\":M, \"T\":T,\n",
    "        \"R\":R, \"Zi\":Zi, \"cov\":cov, \"carry\":carry}. Defaults to False.\n",
    "    method : {'euclid', 'riemann'}\n",
    "        Metric to compute the covariance matrix average. Currently, only\n",
    "        euclidean ASR is supported.\n",
    "    mem_splits : int\n",
    "        Split the array in `mem_splits` segments to save memory.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    clean : array, shape=(n_channels, n_samples)\n",
    "        Clean data.\n",
    "    state : dict\n",
    "        Output ASR parameters {\"M\":M, \"T\":T, \"R\":R, \"Zi\":Zi, \"cov\":cov,\n",
    "        \"carry\":carry}.\n",
    "\n",
    "    \"\"\"\n",
    "    if method == \"riemann\":\n",
    "        warnings.warn(\"Riemannian ASR is not yet supported. Switching back to\"\n",
    "                      \" Euclidean ASR.\")\n",
    "        method == \"euclid\"\n",
    "\n",
    "    # calculate the the actual max dims based on the fraction parameter\n",
    "    if maxdims < 1:\n",
    "        maxdims = np.round(len(data) * maxdims)\n",
    "\n",
    "    # set initial filter conditions of none was passed\n",
    "    if Zi is None:\n",
    "        _, Zi = yulewalk_filter(data, ab=ab, sfreq=sfreq,\n",
    "                                zi=np.ones([len(data), 8]))\n",
    "\n",
    "    # set the number of channels\n",
    "    C, S = data.shape\n",
    "\n",
    "    # set the number of windows\n",
    "    N = np.round(windowlen * sfreq).astype(int)\n",
    "    P = np.round(lookahead * sfreq).astype(int)\n",
    "\n",
    "    # interpolate a portion of the data if no buffer was given\n",
    "    if carry is None:\n",
    "        carry = np.tile(2 * data[:, 0],\n",
    "                        (P, 1)).T - data[:, np.mod(np.arange(P, 0, -1), S)]\n",
    "    data = np.concatenate([carry, data], axis=-1)\n",
    "\n",
    "    # splits = np.ceil(C*C*S*8*8 + C*C*8*s/stepsize + C*S*8*2 + S*8*5)...\n",
    "    splits = mem_splits  # TODO: use this for parallelization MAKE IT A PARAM FIRST\n",
    "\n",
    "    # loop over smaller segments of the data (for memory purposes)\n",
    "    last_trivial = False\n",
    "    last_R = None\n",
    "    for i in range(splits):\n",
    "\n",
    "        # set the current range\n",
    "        i_range = np.arange(i * S // splits,\n",
    "                            np.min([(i + 1) * S // splits, S]),\n",
    "                            dtype=int)\n",
    "\n",
    "        # filter the current window with yule-walker\n",
    "        X, Zi = yulewalk_filter(data[:, i_range + P], sfreq=sfreq,\n",
    "                                zi=Zi, ab=ab, axis=-1)\n",
    "\n",
    "        # compute a moving average covariance\n",
    "        Xcov, cov = \\\n",
    "            ma_filter(N,\n",
    "                      np.reshape(np.multiply(np.reshape(X, (1, C, -1)),\n",
    "                                             np.reshape(X, (C, 1, -1))),\n",
    "                                 (C * C, -1)), cov)\n",
    "\n",
    "        # set indices at which we update the signal\n",
    "        update_at = np.arange(stepsize,\n",
    "                              Xcov.shape[-1] + stepsize - 2,\n",
    "                              stepsize)\n",
    "        update_at = np.minimum(update_at, Xcov.shape[-1]) - 1\n",
    "\n",
    "        # set the previous reconstruction matrix if none was assigned\n",
    "        if last_R is None:\n",
    "            update_at = np.concatenate([[0], update_at])\n",
    "            last_R = np.eye(C)\n",
    "\n",
    "        Xcov = np.reshape(Xcov[:, update_at], (C, C, -1))\n",
    "\n",
    "        # loop through the updating intervals\n",
    "        last_n = 0\n",
    "        for j in range(len(update_at) - 1):\n",
    "\n",
    "            # get the eigenvectors/values.For method 'riemann', this should\n",
    "            # be replaced with PGA/ nonlinear eigenvalues\n",
    "            D, V = np.linalg.eigh(Xcov[:, :, j])\n",
    "\n",
    "            # determine which components to keep\n",
    "            keep = np.logical_or(D < np.sum((T @ V)**2, axis=0),\n",
    "                                 np.arange(C) + 1 < (C - maxdims))\n",
    "            trivial = np.all(keep)\n",
    "\n",
    "            # set the reconstruction matrix (ie. reconstructing artifact\n",
    "            # components using the mixing matrix)\n",
    "            if not trivial:\n",
    "                inv = pinv(np.multiply(keep[:, np.newaxis], V.T @ M))\n",
    "                R = np.real(M @ inv @ V.T)\n",
    "            else:\n",
    "                R = np.eye(C)\n",
    "\n",
    "            # apply the reconstruction\n",
    "            n = update_at[j] + 1\n",
    "            if (not trivial) or (not last_trivial):\n",
    "\n",
    "                subrange = i_range[np.arange(last_n, n)]\n",
    "\n",
    "                # generate a cosine signal\n",
    "                blend_x = np.pi * np.arange(1, n - last_n + 1) / (n - last_n)\n",
    "                blend = (1 - np.cos(blend_x)) / 2\n",
    "\n",
    "                # use cosine blending to replace data with reconstructed data\n",
    "                tmp_data = data[:, subrange]\n",
    "                data[:, subrange] = np.multiply(blend, R @ tmp_data) + \\\n",
    "                                    np.multiply(1 - blend, last_R @ tmp_data) # noqa\n",
    "\n",
    "            # set the parameters for the next iteration\n",
    "            last_n, last_R, last_trivial = n, R, trivial\n",
    "\n",
    "    # assign a new lookahead portion\n",
    "    carry = np.concatenate([carry, data[:, -P:]])\n",
    "    carry = carry[:, -P:]\n",
    "\n",
    "    if return_states:\n",
    "        return data[:, :-P], {\"M\": M, \"T\": T, \"R\": R, \"Zi\": Zi,\n",
    "                              \"cov\": cov, \"carry\": carry}\n",
    "    else:\n",
    "        return data[:, :-P]\n",
    "\n",
    "\n",
    "def clean_windows(X, sfreq, max_bad_chans=0.2, zthresholds=[-3.5, 5],\n",
    "                  win_len=.5, win_overlap=0.66, min_clean_fraction=0.25,\n",
    "                  max_dropout_fraction=0.1):\n",
    "    \"\"\"Remove periods with abnormally high-power content from continuous data.\n",
    "\n",
    "    This function cuts segments from the data which contain high-power\n",
    "    artifacts. Specifically, only windows are retained which have less than a\n",
    "    certain fraction of \"bad\" channels, where a channel is bad in a window if\n",
    "    its power is above or below a given upper/lower threshold (in standard\n",
    "    deviations from a robust estimate of the EEG power distribution in the\n",
    "    channel).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_channels, n_samples)\n",
    "        Continuous data set, assumed to be appropriately high-passed (e.g. >\n",
    "        1Hz or 0.5Hz - 2.0Hz transition band)\n",
    "    max_bad_chans : float\n",
    "        The maximum number or fraction of bad channels that a retained window\n",
    "        may still contain (more than this and it is removed). Reasonable range\n",
    "        is 0.05 (very clean output) to 0.3 (very lax cleaning of only coarse\n",
    "        artifacts) (default=0.2).\n",
    "    zthresholds : 2-tuple\n",
    "        The minimum and maximum standard deviations within which the power of\n",
    "        a channel must lie (relative to a robust estimate of the clean EEG\n",
    "        power distribution in the channel) for it to be considered \"not bad\".\n",
    "        (default=[-3.5, 5]).\n",
    "\n",
    "    The following are detail parameters that usually do not have to be tuned.\n",
    "    If you can't get the function to do what you want, you might consider\n",
    "    adapting these to your data.\n",
    "\n",
    "    win_len : float\n",
    "        Window length that is used to check the data for artifact content.\n",
    "        This is ideally as long as the expected time scale of the artifacts\n",
    "        but not shorter than half a cycle of the high-pass filter that was\n",
    "        used. Default: 1.\n",
    "    win_overlap : float\n",
    "        Window overlap fraction. The fraction of two successive windows that\n",
    "        overlaps. Higher overlap ensures that fewer artifact portions are\n",
    "        going to be missed, but is slower (default=0.66).\n",
    "    min_clean_fraction : float\n",
    "        Minimum fraction that needs to be clean. This is the minimum fraction\n",
    "        of time windows that need to contain essentially uncontaminated EEG.\n",
    "        (default=0.25)\n",
    "    max_dropout_fraction : float\n",
    "        Maximum fraction that can have dropouts. This is the maximum fraction\n",
    "        of time windows that may have arbitrarily low amplitude (e.g., due to\n",
    "        the sensors being unplugged) (default=0.1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    clean : array, shape=(n_channels, n_samples)\n",
    "        Dataset with bad time periods removed.\n",
    "    sample_mask : boolean array, shape=(1, n_samples)\n",
    "        Mask of retained samples (logical array).\n",
    "\n",
    "    \"\"\"\n",
    "    assert 0 < max_bad_chans < 1, \"max_bad_chans must be a fraction !\"\n",
    "\n",
    "    # set internal variables\n",
    "    truncate_quant = [0.0220, 0.6000]\n",
    "    step_sizes = [0.01, 0.01]\n",
    "    shape_range = np.arange(1.7, 3.5, 0.15)\n",
    "    max_bad_chans = np.round(X.shape[0] * max_bad_chans)\n",
    "\n",
    "    # set data indices\n",
    "    [nc, ns] = X.shape\n",
    "    N = int(win_len * sfreq)\n",
    "    offsets = np.int_(np.round(np.arange(0, ns - N, (N * (1 - win_overlap)))))\n",
    "    logging.debug('[ASR] Determining channel-wise rejection thresholds')\n",
    "\n",
    "    wz = np.zeros((nc, len(offsets)))\n",
    "    for ichan in range(nc):\n",
    "\n",
    "        # compute root mean squared amplitude\n",
    "        x = X[ichan, :] ** 2\n",
    "        Y = np.array([np.sqrt(np.sum(x[o:o + N]) / N) for o in offsets])\n",
    "\n",
    "        # fit a distribution to the clean EEG part\n",
    "        mu, sig, alpha, beta = fit_eeg_distribution(\n",
    "            Y, min_clean_fraction, max_dropout_fraction, truncate_quant,\n",
    "            step_sizes, shape_range)\n",
    "        # calculate z scores\n",
    "        wz[ichan] = (Y - mu) / sig\n",
    "\n",
    "    # sort z scores into quantiles\n",
    "    wz[np.isnan(wz)] = np.inf  # Nan to inf\n",
    "    swz = np.sort(wz, axis=0)\n",
    "\n",
    "    # determine which windows to remove\n",
    "    if np.max(zthresholds) > 0:\n",
    "        mask1 = swz[-(np.int32(max_bad_chans) + 1), :] > np.max(zthresholds)\n",
    "    if np.min(zthresholds) < 0:\n",
    "        mask2 = (swz[1 + np.int32(max_bad_chans - 1), :] < np.min(zthresholds))\n",
    "\n",
    "    # combine the two thresholds\n",
    "    remove_mask = np.logical_or.reduce((mask1, mask2))\n",
    "    removed_wins = np.where(remove_mask)\n",
    "\n",
    "    # reconstruct the samples to remove\n",
    "    sample_maskidx = []\n",
    "    for i in range(len(removed_wins[0])):\n",
    "        if i == 0:\n",
    "            sample_maskidx = np.arange(\n",
    "                offsets[removed_wins[0][i]], offsets[removed_wins[0][i]] + N)\n",
    "        else:\n",
    "            sample_maskidx = np.vstack((\n",
    "                sample_maskidx,\n",
    "                np.arange(offsets[removed_wins[0][i]],\n",
    "                          offsets[removed_wins[0][i]] + N)\n",
    "            ))\n",
    "\n",
    "    # delete the bad chunks from the data\n",
    "    sample_mask2remove = np.unique(sample_maskidx)\n",
    "    if sample_mask2remove.size:\n",
    "        clean = np.delete(X, sample_mask2remove, 1)\n",
    "        sample_mask = np.ones((1, ns), dtype=bool)\n",
    "        sample_mask[0, sample_mask2remove] = False\n",
    "    else:\n",
    "        sample_mask = np.ones((1, ns), dtype=bool)\n",
    "\n",
    "\n",
    "    return clean, sample_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamps</th>\n",
       "      <th>Fp1</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>stim</th>\n",
       "      <th>sfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.709562e+09</td>\n",
       "      <td>-37315.566816</td>\n",
       "      <td>-37971.501109</td>\n",
       "      <td>-44301.649249</td>\n",
       "      <td>-39326.821485</td>\n",
       "      <td>-38091.932308</td>\n",
       "      <td>-42685.081683</td>\n",
       "      <td>-39995.362162</td>\n",
       "      <td>-45340.603035</td>\n",
       "      <td>-46383.580134</td>\n",
       "      <td>-44207.906033</td>\n",
       "      <td>-45612.847282</td>\n",
       "      <td>-82818.845847</td>\n",
       "      <td>-47694.107615</td>\n",
       "      <td>-55704.123462</td>\n",
       "      <td>-46313.172139</td>\n",
       "      <td>-56584.022234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.709562e+09</td>\n",
       "      <td>-74676.597080</td>\n",
       "      <td>-75963.789340</td>\n",
       "      <td>-88632.936911</td>\n",
       "      <td>-78996.697545</td>\n",
       "      <td>-76203.310633</td>\n",
       "      <td>-85438.559704</td>\n",
       "      <td>-80021.703842</td>\n",
       "      <td>-90723.853198</td>\n",
       "      <td>-94142.060774</td>\n",
       "      <td>-87977.807281</td>\n",
       "      <td>-89926.566473</td>\n",
       "      <td>-114472.134646</td>\n",
       "      <td>-94306.346095</td>\n",
       "      <td>-180493.242203</td>\n",
       "      <td>-93103.375209</td>\n",
       "      <td>-106202.749157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.709562e+09</td>\n",
       "      <td>-70195.832276</td>\n",
       "      <td>-71380.295918</td>\n",
       "      <td>-84370.906278</td>\n",
       "      <td>-75097.167503</td>\n",
       "      <td>-71921.431651</td>\n",
       "      <td>-81097.135675</td>\n",
       "      <td>-75507.679642</td>\n",
       "      <td>-86529.682461</td>\n",
       "      <td>-93178.342960</td>\n",
       "      <td>-84785.575841</td>\n",
       "      <td>-86176.167271</td>\n",
       "      <td>-113766.713591</td>\n",
       "      <td>-90730.156389</td>\n",
       "      <td>-180578.938792</td>\n",
       "      <td>-89466.031130</td>\n",
       "      <td>-104809.877850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.709562e+09</td>\n",
       "      <td>-75372.898623</td>\n",
       "      <td>-76687.985860</td>\n",
       "      <td>-89306.842006</td>\n",
       "      <td>-79372.072741</td>\n",
       "      <td>-76887.944566</td>\n",
       "      <td>-86097.712648</td>\n",
       "      <td>-80749.387234</td>\n",
       "      <td>-91372.679636</td>\n",
       "      <td>-93151.386756</td>\n",
       "      <td>-85667.352160</td>\n",
       "      <td>-87404.350925</td>\n",
       "      <td>-113962.917204</td>\n",
       "      <td>-91830.532769</td>\n",
       "      <td>-180690.921031</td>\n",
       "      <td>-90602.080894</td>\n",
       "      <td>-105176.401755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.709562e+09</td>\n",
       "      <td>-71427.502802</td>\n",
       "      <td>-72627.389148</td>\n",
       "      <td>-85527.877274</td>\n",
       "      <td>-76314.622320</td>\n",
       "      <td>-73081.621299</td>\n",
       "      <td>-82298.899567</td>\n",
       "      <td>-76746.994465</td>\n",
       "      <td>-87678.472719</td>\n",
       "      <td>-94171.565076</td>\n",
       "      <td>-87515.394391</td>\n",
       "      <td>-89263.390215</td>\n",
       "      <td>-114363.102837</td>\n",
       "      <td>-93716.796484</td>\n",
       "      <td>-180443.084889</td>\n",
       "      <td>-92489.417492</td>\n",
       "      <td>-106010.837079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamps           Fp1           Fp2            C3            C4  \\\n",
       "0  1.709562e+09 -37315.566816 -37971.501109 -44301.649249 -39326.821485   \n",
       "1  1.709562e+09 -74676.597080 -75963.789340 -88632.936911 -78996.697545   \n",
       "2  1.709562e+09 -70195.832276 -71380.295918 -84370.906278 -75097.167503   \n",
       "3  1.709562e+09 -75372.898623 -76687.985860 -89306.842006 -79372.072741   \n",
       "4  1.709562e+09 -71427.502802 -72627.389148 -85527.877274 -76314.622320   \n",
       "\n",
       "             P7            P8            O1            O2            F7  \\\n",
       "0 -38091.932308 -42685.081683 -39995.362162 -45340.603035 -46383.580134   \n",
       "1 -76203.310633 -85438.559704 -80021.703842 -90723.853198 -94142.060774   \n",
       "2 -71921.431651 -81097.135675 -75507.679642 -86529.682461 -93178.342960   \n",
       "3 -76887.944566 -86097.712648 -80749.387234 -91372.679636 -93151.386756   \n",
       "4 -73081.621299 -82298.899567 -76746.994465 -87678.472719 -94171.565076   \n",
       "\n",
       "             F8            F3             F4            T7             T8  \\\n",
       "0 -44207.906033 -45612.847282  -82818.845847 -47694.107615  -55704.123462   \n",
       "1 -87977.807281 -89926.566473 -114472.134646 -94306.346095 -180493.242203   \n",
       "2 -84785.575841 -86176.167271 -113766.713591 -90730.156389 -180578.938792   \n",
       "3 -85667.352160 -87404.350925 -113962.917204 -91830.532769 -180690.921031   \n",
       "4 -87515.394391 -89263.390215 -114363.102837 -93716.796484 -180443.084889   \n",
       "\n",
       "             P3             P4  stim  sfreq  \n",
       "0 -46313.172139  -56584.022234   0.0    125  \n",
       "1 -93103.375209 -106202.749157   0.0    125  \n",
       "2 -89466.031130 -104809.877850   0.0    125  \n",
       "3 -90602.080894 -105176.401755   0.0    125  \n",
       "4 -92489.417492 -106010.837079   0.0    125  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import os\n",
    "path = r'Aanand_19_01.csv'\n",
    "sfreq = 120\n",
    "#ch_names = ['Fp2', 'F4', 'F8', 'T8', 'Fp1', 'F3', 'F7', 'T7', 'Cz',\n",
    "#            'C4', 'P4', 'O2', 'Pz', 'C3', 'P3', 'O1','stim']\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.drop('stim', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp.drop('sfreq', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamps</th>\n",
       "      <th>Fp1</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.709562e+09</td>\n",
       "      <td>-37315.566816</td>\n",
       "      <td>-37971.501109</td>\n",
       "      <td>-44301.649249</td>\n",
       "      <td>-39326.821485</td>\n",
       "      <td>-38091.932308</td>\n",
       "      <td>-42685.081683</td>\n",
       "      <td>-39995.362162</td>\n",
       "      <td>-45340.603035</td>\n",
       "      <td>-46383.580134</td>\n",
       "      <td>-44207.906033</td>\n",
       "      <td>-45612.847282</td>\n",
       "      <td>-82818.845847</td>\n",
       "      <td>-47694.107615</td>\n",
       "      <td>-55704.123462</td>\n",
       "      <td>-46313.172139</td>\n",
       "      <td>-56584.022234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.709562e+09</td>\n",
       "      <td>-74676.597080</td>\n",
       "      <td>-75963.789340</td>\n",
       "      <td>-88632.936911</td>\n",
       "      <td>-78996.697545</td>\n",
       "      <td>-76203.310633</td>\n",
       "      <td>-85438.559704</td>\n",
       "      <td>-80021.703842</td>\n",
       "      <td>-90723.853198</td>\n",
       "      <td>-94142.060774</td>\n",
       "      <td>-87977.807281</td>\n",
       "      <td>-89926.566473</td>\n",
       "      <td>-114472.134646</td>\n",
       "      <td>-94306.346095</td>\n",
       "      <td>-180493.242203</td>\n",
       "      <td>-93103.375209</td>\n",
       "      <td>-106202.749157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.709562e+09</td>\n",
       "      <td>-70195.832276</td>\n",
       "      <td>-71380.295918</td>\n",
       "      <td>-84370.906278</td>\n",
       "      <td>-75097.167503</td>\n",
       "      <td>-71921.431651</td>\n",
       "      <td>-81097.135675</td>\n",
       "      <td>-75507.679642</td>\n",
       "      <td>-86529.682461</td>\n",
       "      <td>-93178.342960</td>\n",
       "      <td>-84785.575841</td>\n",
       "      <td>-86176.167271</td>\n",
       "      <td>-113766.713591</td>\n",
       "      <td>-90730.156389</td>\n",
       "      <td>-180578.938792</td>\n",
       "      <td>-89466.031130</td>\n",
       "      <td>-104809.877850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.709562e+09</td>\n",
       "      <td>-75372.898623</td>\n",
       "      <td>-76687.985860</td>\n",
       "      <td>-89306.842006</td>\n",
       "      <td>-79372.072741</td>\n",
       "      <td>-76887.944566</td>\n",
       "      <td>-86097.712648</td>\n",
       "      <td>-80749.387234</td>\n",
       "      <td>-91372.679636</td>\n",
       "      <td>-93151.386756</td>\n",
       "      <td>-85667.352160</td>\n",
       "      <td>-87404.350925</td>\n",
       "      <td>-113962.917204</td>\n",
       "      <td>-91830.532769</td>\n",
       "      <td>-180690.921031</td>\n",
       "      <td>-90602.080894</td>\n",
       "      <td>-105176.401755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.709562e+09</td>\n",
       "      <td>-71427.502802</td>\n",
       "      <td>-72627.389148</td>\n",
       "      <td>-85527.877274</td>\n",
       "      <td>-76314.622320</td>\n",
       "      <td>-73081.621299</td>\n",
       "      <td>-82298.899567</td>\n",
       "      <td>-76746.994465</td>\n",
       "      <td>-87678.472719</td>\n",
       "      <td>-94171.565076</td>\n",
       "      <td>-87515.394391</td>\n",
       "      <td>-89263.390215</td>\n",
       "      <td>-114363.102837</td>\n",
       "      <td>-93716.796484</td>\n",
       "      <td>-180443.084889</td>\n",
       "      <td>-92489.417492</td>\n",
       "      <td>-106010.837079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamps           Fp1           Fp2            C3            C4  \\\n",
       "0  1.709562e+09 -37315.566816 -37971.501109 -44301.649249 -39326.821485   \n",
       "1  1.709562e+09 -74676.597080 -75963.789340 -88632.936911 -78996.697545   \n",
       "2  1.709562e+09 -70195.832276 -71380.295918 -84370.906278 -75097.167503   \n",
       "3  1.709562e+09 -75372.898623 -76687.985860 -89306.842006 -79372.072741   \n",
       "4  1.709562e+09 -71427.502802 -72627.389148 -85527.877274 -76314.622320   \n",
       "\n",
       "             P7            P8            O1            O2            F7  \\\n",
       "0 -38091.932308 -42685.081683 -39995.362162 -45340.603035 -46383.580134   \n",
       "1 -76203.310633 -85438.559704 -80021.703842 -90723.853198 -94142.060774   \n",
       "2 -71921.431651 -81097.135675 -75507.679642 -86529.682461 -93178.342960   \n",
       "3 -76887.944566 -86097.712648 -80749.387234 -91372.679636 -93151.386756   \n",
       "4 -73081.621299 -82298.899567 -76746.994465 -87678.472719 -94171.565076   \n",
       "\n",
       "             F8            F3             F4            T7             T8  \\\n",
       "0 -44207.906033 -45612.847282  -82818.845847 -47694.107615  -55704.123462   \n",
       "1 -87977.807281 -89926.566473 -114472.134646 -94306.346095 -180493.242203   \n",
       "2 -84785.575841 -86176.167271 -113766.713591 -90730.156389 -180578.938792   \n",
       "3 -85667.352160 -87404.350925 -113962.917204 -91830.532769 -180690.921031   \n",
       "4 -87515.394391 -89263.390215 -114363.102837 -93716.796484 -180443.084889   \n",
       "\n",
       "             P3             P4  \n",
       "0 -46313.172139  -56584.022234  \n",
       "1 -93103.375209 -106202.749157  \n",
       "2 -89466.031130 -104809.877850  \n",
       "3 -90602.080894 -105176.401755  \n",
       "4 -92489.417492 -106010.837079  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=16, n_times=65257\n",
      "    Range : 0 ... 65256 =      0.000 ...   543.800 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details open>\n",
       "    <summary><strong>General</strong></summary>\n",
       "    <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "        <tr>\n",
       "            <th>Measurement date</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Experimenter</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Participant</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "    </table>\n",
       "    </details>\n",
       "    <details open>\n",
       "        <summary><strong>Channels</strong></summary>\n",
       "        <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "            <tr>\n",
       "                <th>Digitized points</th>\n",
       "                \n",
       "                <td>Not available</td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Good channels</th>\n",
       "                <td>16 EEG</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Bad channels</th>\n",
       "                <td>None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>EOG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>ECG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        </details>\n",
       "        <details open>\n",
       "            <summary><strong>Data</strong></summary>\n",
       "            <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "                \n",
       "                <tr>\n",
       "                    <th>Sampling frequency</th>\n",
       "                    <td>120.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Highpass</th>\n",
       "                    <td>0.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Lowpass</th>\n",
       "                    <td>60.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Duration</th>\n",
       "                    <td>00:09:04 (HH:MM:SS)</td>\n",
       "                </tr>\n",
       "                \n",
       "            </table>\n",
       "            </details>"
      ],
      "text/plain": [
       "<RawArray | 16 x 65257 (543.8 s), ~8.0 MB, data loaded>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_data = df.iloc[:,1:18].values.T\n",
    "eeg_data[:-1] = eeg_data[:-1] * (10*(-6))\n",
    "eeg_data[:-1] = eeg_data[:-1] / 4\n",
    "\n",
    "ch_names = ['Fp1',\t'Fp2'\t,'C3'\t,'C4'\t,'P7'\t,'P8'\t,'O1'\t,'O2'\t,'F7'\t,'F8'\t,'F3'\t,'F4'\t,'T7'\t,'T8'\t,'P3'\t,'P4']\n",
    "info = mne.create_info(ch_names = ch_names, sfreq = sfreq, ch_types = ( [\"eeg\" ]*16))\n",
    "raw = mne.io.RawArray(eeg_data, info)\n",
    "raw.set_eeg_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 397 samples (3.308 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "raw.filter(l_freq=1,h_freq=30)\n",
    "asr = ASR(sfreq=sfreq, cutoff=15)\n",
    "asr.fit(raw.copy())\n",
    "raw_asr = asr.transform(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "1359 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "duration = 0.4\n",
    "\n",
    "epochs=mne.make_fixed_length_epochs(raw_asr, duration = duration, overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 1359 events and 48 original time points ...\n",
      "0 bad epochs dropped\n",
      "Total number of epochs created: 1359\n"
     ]
    }
   ],
   "source": [
    "epochs.drop_bad()  # This will drop bad epochs\n",
    "num_epochs = len(epochs)\n",
    "print(\"Total number of epochs created:\", num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 1359 events and 48 original time points ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 1.51863626e-07,  2.28917712e+02,  2.07631159e+02, ...,\n",
       "          3.03898034e+02,  4.21609045e+02,  2.58825876e+02],\n",
       "        [ 1.56809173e-07,  2.90406152e+02,  2.05601740e+02, ...,\n",
       "          3.48534328e+02,  3.42127661e+02,  1.30336362e+02],\n",
       "        [ 1.65159184e-07,  2.50658346e+02,  1.96978421e+02, ...,\n",
       "          2.92789804e+02,  2.98516165e+02,  1.68468221e+02],\n",
       "        ...,\n",
       "        [ 3.29275249e-07, -7.96901495e+02, -1.02746626e+03, ...,\n",
       "         -5.55602270e+02, -4.61885761e+02, -5.04774478e+02],\n",
       "        [-4.59357951e-07,  1.57692153e+02,  1.97838666e+02, ...,\n",
       "         -3.20947718e+01, -1.83391000e+02,  6.14701135e+00],\n",
       "        [ 2.16238753e-07, -5.57506789e+02, -5.74778221e+02, ...,\n",
       "         -5.49604195e+02, -4.28587693e+02, -8.60802829e+01]],\n",
       "\n",
       "       [[-2.86556298e+00, -3.95837417e+01,  2.09640882e+02, ...,\n",
       "         -4.17929316e+02, -4.26441258e+02,  2.50258895e+00],\n",
       "        [-5.49690676e+01, -1.88605187e+01,  2.31760775e+02, ...,\n",
       "         -5.83451949e+02, -4.79648046e+02,  8.34756464e+01],\n",
       "        [ 4.52970238e+01,  4.57982038e+01,  2.03578535e+02, ...,\n",
       "         -4.39057430e+02, -3.92996037e+02,  5.78781635e+01],\n",
       "        ...,\n",
       "        [-7.29354264e+02, -6.84252771e+02, -3.70928671e+02, ...,\n",
       "          3.29150551e+02,  3.36947392e+02,  4.56671569e+02],\n",
       "        [ 3.78445144e+02,  3.90136150e+02, -7.08887474e+01, ...,\n",
       "          3.50726390e+02,  3.59275572e+02, -4.21138044e+02],\n",
       "        [ 4.10524459e+01, -9.24596155e+01, -2.87016359e+02, ...,\n",
       "          6.78921677e+02,  4.66517510e+02,  1.55823422e+02]],\n",
       "\n",
       "       [[ 3.23028684e+02,  1.95530597e+01, -5.35538709e+02, ...,\n",
       "          6.74953686e+02,  3.72509416e+02, -9.49725581e+01],\n",
       "        [ 3.69160789e+02, -6.91773256e+01, -6.70849736e+02, ...,\n",
       "          7.98789592e+02,  4.55973394e+02, -1.24748082e+02],\n",
       "        [ 3.09002234e+02, -3.51214356e+01, -5.35528975e+02, ...,\n",
       "          6.48412363e+02,  3.73420198e+02, -1.55434338e+02],\n",
       "        ...,\n",
       "        [ 3.09735685e+02,  6.89157485e+01,  2.84386764e+02, ...,\n",
       "         -3.62100840e+02, -8.97247379e+02, -9.81466345e+02],\n",
       "        [-8.08558130e+02, -1.22502365e+02,  7.05525230e+02, ...,\n",
       "         -6.81388569e+02, -1.06189477e+02,  6.85099528e+02],\n",
       "        [-3.04942160e+01,  1.84175013e+02,  6.96476546e+02, ...,\n",
       "         -9.08235625e+02, -9.29326913e+02, -7.16841050e+02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-7.95011502e+01, -1.35722713e+02, -1.46421117e+02, ...,\n",
       "         -3.49961028e+02, -2.12944756e+02, -1.85047760e+02],\n",
       "        [ 3.83671768e+02,  1.23917981e+02,  4.41556793e+01, ...,\n",
       "         -3.33490274e+02, -2.60880204e+02, -2.63599925e+02],\n",
       "        [ 3.43531057e+02,  1.14612386e+02,  7.09888073e+01, ...,\n",
       "         -5.00781876e+02, -4.98373333e+02, -4.86701344e+02],\n",
       "        ...,\n",
       "        [-5.82475575e+02,  9.30560868e+01,  2.70484187e+02, ...,\n",
       "          6.46061204e+02,  6.39629983e+02,  5.18019191e+02],\n",
       "        [-5.77761523e+02, -4.65189387e+02, -4.37434100e+02, ...,\n",
       "          4.15032664e+02,  3.02836694e+02,  2.78773389e+02],\n",
       "        [-8.08057560e+02,  2.80372719e+01,  2.83030639e+02, ...,\n",
       "          5.67086589e+02,  3.90207412e+02,  3.89265694e+02]],\n",
       "\n",
       "       [[-4.45615211e+02, -3.48076607e+02,  9.67188785e+01, ...,\n",
       "          1.94597670e+02, -4.02384234e+00, -1.27343834e+02],\n",
       "        [-5.03308211e+02, -5.14789719e+02, -2.79482315e+02, ...,\n",
       "          2.11612135e+02,  2.20555237e+01, -1.23780071e+02],\n",
       "        [-6.85807338e+02, -6.81674095e+02, -4.38748662e+02, ...,\n",
       "          1.72051103e+02, -3.56755524e+01, -1.78942528e+02],\n",
       "        ...,\n",
       "        [ 4.75490922e+02,  3.93227989e+02,  2.78537512e+02, ...,\n",
       "         -1.99289210e+01, -6.46006247e+01, -9.96665855e+01],\n",
       "        [ 5.81484670e+02,  6.21006599e+02,  3.28307056e+02, ...,\n",
       "         -2.27991223e+02,  3.58848111e+01,  2.61432931e+02],\n",
       "        [ 5.73111590e+02,  4.72930820e+02,  1.41421414e+02, ...,\n",
       "         -2.39876952e+02, -1.90629506e+02, -1.90153280e+02]],\n",
       "\n",
       "       [[ 2.91660664e+02,  8.97171296e+02,  8.28588965e+02, ...,\n",
       "         -3.62512236e+02, -4.36785798e+02, -4.35066223e+02],\n",
       "        [ 3.09674808e+02,  9.40249116e+02,  8.22628945e+02, ...,\n",
       "         -3.09272553e+02, -4.09811811e+02, -3.87694124e+02],\n",
       "        [ 2.84300354e+02,  9.84179287e+02,  9.32262579e+02, ...,\n",
       "         -1.81882172e+02, -2.53678545e+02, -2.32716157e+02],\n",
       "        ...,\n",
       "        [-3.91953231e+01,  2.52766315e+02,  5.77878099e+02, ...,\n",
       "          1.11216475e+03,  1.28853326e+03,  1.05049596e+03],\n",
       "        [-2.72510186e+02, -1.09590368e+03, -9.82772577e+02, ...,\n",
       "         -9.72858592e+01, -2.97411255e+01,  1.08861600e+02],\n",
       "        [-4.26431117e+02, -7.98691063e+02, -8.71280790e+02, ...,\n",
       "          1.22481436e+03,  1.44704586e+03,  1.27925477e+03]]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 1359 events and 48 original time points ...\n",
      "Using data from preloaded Raw for 251 events and 48 original time points ...\n",
      "Using data from preloaded Raw for 251 events and 48 original time points ...\n",
      "Using data from preloaded Raw for 251 events and 48 original time points ...\n",
      "Not setting metadata\n",
      "753 matching events found\n",
      "No baseline correction applied\n",
      "Number of epochs for lev1: 251\n",
      "Number of epochs for lev2: 251\n",
      "Number of epochs for lev3: 251\n",
      "Total number of selected epochs: 753\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "\n",
    "eeg_data = epochs.get_data()\n",
    "\n",
    "condition_ranges = {'lev1': (100/duration, 200/duration),\n",
    "                    'lev2': (280/duration, 380/duration),\n",
    "                    'lev3': (420/duration, 520/duration)}\n",
    "\n",
    "epochs_by_condition = {}\n",
    "selected_epochs = []\n",
    "\n",
    "for condition, (start_epoch, end_epoch) in condition_ranges.items():\n",
    "    start_epoch = int(start_epoch)\n",
    "    end_epoch = int(end_epoch)\n",
    "    condition_epochs = epochs[start_epoch:end_epoch+1].copy()\n",
    "    epochs_by_condition[condition] = condition_epochs\n",
    "    selected_epochs.append(condition_epochs)\n",
    "\n",
    "selected_epochs = mne.concatenate_epochs(selected_epochs)\n",
    "\n",
    "for condition, epoch_data in epochs_by_condition.items():\n",
    "    num_epochs = len(epoch_data)\n",
    "    print(f\"Number of epochs for {condition}: {num_epochs}\")\n",
    "\n",
    "print(f\"Total number of selected epochs: {len(selected_epochs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 251 events and 48 original time points ...\n",
      "Epoch array shape for condition lev1: (251, 16, 48)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "condition_of_interest = 'lev1'\n",
    "epoch_array_for_condition = epochs_by_condition[condition_of_interest]\n",
    "print(f\"Epoch array shape for condition {condition_of_interest}: {epoch_array_for_condition.get_data().shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26490066225165565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = selected_epochs.get_data(copy=True)\n",
    "y = np.concatenate([np.full(len(epochs), i) for i, epochs in enumerate(epochs_by_condition.values())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train.reshape(len(X_train), -1), y_train)\n",
    "\n",
    "y_pred = model.predict(X_test.reshape(len(X_test), -1))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.609271523178808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators= 175, random_state=42)  # Increased n_estimators for better performance\n",
    "rf_model.fit(X_train.reshape(len(X_train), -1), y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test.reshape(len(X_test), -1))\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.5761589403973509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the Gradient Boosting classifier\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train.reshape(len(X_train), -1), y_train)\n",
    "\n",
    "# Predict labels on the test set\n",
    "y_pred_gb = gb_model.predict(X_test.reshape(len(X_test), -1))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_gb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Accuracy: 0.39072847682119205\n",
      "SVM Accuracy: 0.48344370860927155\n",
      "Multilayer Perceptron Accuracy: 0.4370860927152318\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X, y, X_train, X_test, y_train, y_test are defined as in your code\n",
    "\n",
    "# K-Nearest Neighbors (k-NN)\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train.reshape(len(X_train), -1), y_train)\n",
    "knn_y_pred = knn_model.predict(X_test.reshape(len(X_test), -1))\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
    "print(\"K-Nearest Neighbors Accuracy:\", knn_accuracy)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train.reshape(len(X_train), -1), y_train)\n",
    "svm_y_pred = svm_model.predict(X_test.reshape(len(X_test), -1))\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "\n",
    "# Multilayer Perceptron (MLP)\n",
    "mlp_model = MLPClassifier()\n",
    "mlp_model.fit(X_train.reshape(len(X_train), -1), y_train)\n",
    "mlp_y_pred = mlp_model.predict(X_test.reshape(len(X_test), -1))\n",
    "mlp_accuracy = accuracy_score(y_test, mlp_y_pred)\n",
    "print(\"Multilayer Perceptron Accuracy:\", mlp_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
